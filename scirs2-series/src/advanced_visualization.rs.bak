//! Ultra-Advanced Time Series Visualization Module
//!
//! This module provides state-of-the-art visualization capabilities for time series data,
//! including AI-powered visual analytics, real-time streaming visualization, 3D plotting,
//! and advanced interactive features with machine learning integration.
//!
//! # Features
//!
//! - **AI-Powered Visual Analytics**: Automated pattern recognition and visualization suggestions
//! - **Real-time Streaming Plots**: Live updating visualizations for streaming data
//! - **3D and Multi-dimensional Visualization**: Complex data relationships in 3D space
//! - **Interactive Machine Learning Plots**: Visualize ML model predictions and uncertainties
//! - **Advanced Statistical Overlays**: Automated statistical annotations and insights
//! - **Cross-platform Rendering**: WebGL, Canvas, SVG, and native rendering
//! - **Performance-Optimized**: Handles millions of data points with smooth interactions
//! - **Collaborative Features**: Real-time sharing and annotation capabilities
//! - **Accessibility Features**: Screen reader support and color-blind friendly palettes

use ndarray::{Array1, Array2, Array3};
use std::collections::{HashMap, VecDeque};
use std::sync::{Arc, Mutex};
use std::time::{Duration, Instant};
use crate::error::{Result, TimeSeriesError};

/// Ultra-advanced plot configuration with AI assistance
#[derive(Debug, Clone)]
pub struct UltraPlotConfig {
    /// Basic plot dimensions
    pub width: u32,
    pub height: u32,
    
    /// Advanced rendering options
    pub renderer: RenderingEngine,
    pub anti_aliasing: bool,
    pub hardware_acceleration: bool,
    pub max_fps: u32,
    
    /// AI-powered features
    pub enable_ai_insights: bool,
    pub auto_pattern_detection: bool,
    pub smart_axis_scaling: bool,
    pub intelligent_color_schemes: bool,
    
    /// Accessibility features
    pub color_blind_friendly: bool,
    pub high_contrast_mode: bool,
    pub screen_reader_support: bool,
    pub keyboard_navigation: bool,
    
    /// Performance optimization
    pub level_of_detail: LevelOfDetail,
    pub data_decimation: DataDecimationConfig,
    pub progressive_rendering: bool,
    pub memory_limit_mb: usize,
}

impl Default for UltraPlotConfig {
    fn default() -> Self {
        Self {
            width: 1920,
            height: 1080,
            renderer: RenderingEngine::WebGL,
            anti_aliasing: true,
            hardware_acceleration: true,
            max_fps: 60,
            enable_ai_insights: true,
            auto_pattern_detection: true,
            smart_axis_scaling: true,
            intelligent_color_schemes: true,
            color_blind_friendly: false,
            high_contrast_mode: false,
            screen_reader_support: false,
            keyboard_navigation: true,
            level_of_detail: LevelOfDetail::default(),
            data_decimation: DataDecimationConfig::default(),
            progressive_rendering: true,
            memory_limit_mb: 1024,
        }
    }
}

/// Rendering engine options
#[derive(Debug, Clone, Copy)]
pub enum RenderingEngine {
    /// High-performance WebGL rendering
    WebGL,
    /// Canvas 2D rendering
    Canvas2D,
    /// SVG vector graphics
    SVG,
    /// Native platform rendering
    Native,
    /// GPU-accelerated custom renderer
    GpuAccelerated,
}

/// Level of detail configuration for large datasets
#[derive(Debug, Clone)]
pub struct LevelOfDetail {
    /// Enable automatic LOD
    pub enabled: bool,
    /// Thresholds for different detail levels
    pub thresholds: Vec<usize>,
    /// Rendering strategies per level
    pub strategies: HashMap<usize, RenderingStrategy>,
}

impl Default for LevelOfDetail {
    fn default() -> Self {
        let mut strategies = HashMap::new();
        strategies.insert(0, RenderingStrategy::FullDetail);
        strategies.insert(10_000, RenderingStrategy::Decimated { factor: 2 });
        strategies.insert(100_000, RenderingStrategy::Decimated { factor: 10 });
        strategies.insert(1_000_000, RenderingStrategy::Statistical);
        
        Self {
            enabled: true,
            thresholds: vec![10_000, 100_000, 1_000_000],
            strategies,
        }
    }
}

/// Rendering strategies for different data sizes
#[derive(Debug, Clone)]
pub enum RenderingStrategy {
    /// Render all data points
    FullDetail,
    /// Decimate data by factor
    Decimated { factor: usize },
    /// Show statistical summary (mean, min, max bands)
    Statistical,
    /// Heatmap representation
    Heatmap,
    /// Density plots
    Density,
}

/// Data decimation configuration
#[derive(Debug, Clone)]
pub struct DataDecimationConfig {
    /// Enable automatic decimation
    pub enabled: bool,
    /// Decimation algorithm
    pub algorithm: DecimationAlgorithm,
    /// Preserve important features
    pub preserve_peaks: bool,
    pub preserve_anomalies: bool,
    pub preserve_trends: bool,
}

impl Default for DataDecimationConfig {
    fn default() -> Self {
        Self {
            enabled: true,
            algorithm: DecimationAlgorithm::LargestTriangleThreeBuckets,
            preserve_peaks: true,
            preserve_anomalies: true,
            preserve_trends: true,
        }
    }
}

/// Decimation algorithms for reducing data while preserving important features
#[derive(Debug, Clone, Copy)]
pub enum DecimationAlgorithm {
    /// Simple uniform sampling
    UniformSampling,
    /// Largest Triangle Three Buckets (LTTB)
    LargestTriangleThreeBuckets,
    /// Douglas-Peucker line simplification
    DouglasPeucker,
    /// Adaptive sampling based on local variance
    AdaptiveSampling,
    /// Perceptually important point sampling
    PerceptualSampling,
}

/// AI-powered visual insights
#[derive(Debug, Clone)]
pub struct VisualInsights {
    /// Detected patterns
    pub patterns: Vec<PatternInsight>,
    /// Suggested visualizations
    pub visualization_suggestions: Vec<VisualizationSuggestion>,
    /// Anomalies detected in visualization
    pub visual_anomalies: Vec<VisualAnomaly>,
    /// Statistical insights
    pub statistical_insights: Vec<StatisticalInsight>,
    /// Correlation insights
    pub correlation_insights: Vec<CorrelationInsight>,
}

/// Pattern insights detected by AI
#[derive(Debug, Clone)]
pub struct PatternInsight {
    /// Pattern type
    pub pattern_type: PatternType,
    /// Confidence score (0.0 to 1.0)
    pub confidence: f64,
    /// Location in data
    pub start_index: usize,
    pub end_index: usize,
    /// Pattern parameters
    pub parameters: HashMap<String, f64>,
    /// Natural language description
    pub description: String,
}

/// Types of patterns that can be detected
#[derive(Debug, Clone, Copy)]
pub enum PatternType {
    /// Seasonal patterns
    Seasonal,
    /// Trend patterns
    Trend,
    /// Cyclical patterns
    Cyclical,
    /// Change points
    ChangePoint,
    /// Anomalies
    Anomaly,
    /// Recurring motifs
    Motif,
    /// Periodic spikes
    PeriodicSpikes,
    /// Level shifts
    LevelShift,
}

/// Visualization suggestions generated by AI
#[derive(Debug, Clone)]
pub struct VisualizationSuggestion {
    /// Suggested plot type
    pub plot_type: SuggestedPlotType,
    /// Rationale for suggestion
    pub rationale: String,
    /// Expected effectiveness score
    pub effectiveness_score: f64,
    /// Required parameters
    pub parameters: HashMap<String, String>,
}

/// AI-suggested plot types
#[derive(Debug, Clone)]
pub enum SuggestedPlotType {
    /// Time series line plot
    TimeSeries,
    /// Autocorrelation function plot
    AutocorrelationFunction,
    /// Spectral density plot
    SpectralDensity,
    /// Phase space plot
    PhaseSpace,
    /// Recurrence plot
    RecurrencePlot,
    /// Wavelet scalogram
    WaveletScalogram,
    /// Box plot for distribution analysis
    BoxPlot,
    /// Violin plot for detailed distribution
    ViolinPlot,
    /// Heatmap for correlation matrix
    CorrelationHeatmap,
    /// 3D surface plot
    Surface3D,
}

/// Visual anomalies detected in plots
#[derive(Debug, Clone)]
pub struct VisualAnomaly {
    /// Anomaly type
    pub anomaly_type: VisualAnomalyType,
    /// Location
    pub x: f64,
    pub y: f64,
    /// Severity score
    pub severity: f64,
    /// Description
    pub description: String,
}

/// Types of visual anomalies
#[derive(Debug, Clone, Copy)]
pub enum VisualAnomalyType {
    /// Data point anomaly
    PointAnomaly,
    /// Contextual anomaly
    ContextualAnomaly,
    /// Collective anomaly
    CollectiveAnomaly,
    /// Visual clutter
    VisualClutter,
    /// Misleading representation
    MisleadingVisualization,
}

/// Statistical insights for visualization
#[derive(Debug, Clone)]
pub struct StatisticalInsight {
    /// Insight type
    pub insight_type: StatisticalInsightType,
    /// Statistical value
    pub value: f64,
    /// Confidence interval
    pub confidence_interval: Option<(f64, f64)>,
    /// P-value if applicable
    pub p_value: Option<f64>,
    /// Natural language description
    pub description: String,
}

/// Types of statistical insights
#[derive(Debug, Clone, Copy)]
pub enum StatisticalInsightType {
    /// Normality test result
    NormalityTest,
    /// Stationarity test result
    StationarityTest,
    /// Trend significance
    TrendSignificance,
    /// Seasonality strength
    SeasonalityStrength,
    /// Autocorrelation significance
    AutocorrelationSignificance,
    /// Changepoint probability
    ChangepointProbability,
}

/// Correlation insights between multiple series
#[derive(Debug, Clone)]
pub struct CorrelationInsight {
    /// Series names
    pub series1: String,
    pub series2: String,
    /// Correlation coefficient
    pub correlation: f64,
    /// Lag at maximum correlation
    pub optimal_lag: i32,
    /// Correlation type
    pub correlation_type: CorrelationType,
    /// Significance
    pub p_value: f64,
}

/// Types of correlation analysis
#[derive(Debug, Clone, Copy)]
pub enum CorrelationType {
    /// Pearson correlation
    Pearson,
    /// Spearman rank correlation
    Spearman,
    /// Cross-correlation
    CrossCorrelation,
    /// Mutual information
    MutualInformation,
    /// Transfer entropy
    TransferEntropy,
}

/// Real-time streaming visualization
#[derive(Debug)]
pub struct StreamingVisualization {
    /// Configuration
    config: UltraPlotConfig,
    /// Data buffer
    data_buffer: Arc<Mutex<VecDeque<(f64, f64)>>>,
    /// Buffer size limit
    buffer_size: usize,
    /// Update frequency
    update_frequency: Duration,
    /// Last update time
    last_update: Instant,
    /// Performance metrics
    performance_metrics: PerformanceMetrics,
    /// AI insights
    ai_insights: Option<VisualInsights>,
}

/// Performance metrics for visualization
#[derive(Debug, Clone)]
pub struct PerformanceMetrics {
    /// Frames per second
    pub fps: f64,
    /// Render time per frame
    pub render_time_ms: f64,
    /// Memory usage
    pub memory_usage_mb: f64,
    /// GPU utilization
    pub gpu_utilization: f64,
    /// Data throughput (points per second)
    pub data_throughput: f64,
}

impl Default for PerformanceMetrics {
    fn default() -> Self {
        Self {
            fps: 0.0,
            render_time_ms: 0.0,
            memory_usage_mb: 0.0,
            gpu_utilization: 0.0,
            data_throughput: 0.0,
        }
    }
}

impl StreamingVisualization {
    /// Create new streaming visualization
    pub fn new(config: UltraPlotConfig, buffer_size: usize) -> Self {
        Self {
            config,
            data_buffer: Arc::new(Mutex::new(VecDeque::with_capacity(buffer_size))),
            buffer_size,
            update_frequency: Duration::from_millis(16), // ~60 FPS
            last_update: Instant::now(),
            performance_metrics: PerformanceMetrics::default(),
            ai_insights: None,
        }
    }
    
    /// Add data point to streaming visualization
    pub fn add_data_point(&mut self, time: f64, value: f64) -> Result<()> {
        let mut buffer = self.data_buffer.lock()
            .map_err(|_| TimeSeriesError::ComputationError("Failed to acquire buffer lock".to_string()))?;
        
        buffer.push_back((time, value));
        
        if buffer.len() > self.buffer_size {
            buffer.pop_front();
        }
        
        // Update performance metrics
        self.update_performance_metrics()?;
        
        Ok(())
    }
    
    /// Update AI insights for streaming data
    pub fn update_ai_insights(&mut self) -> Result<()> {
        if !self.config.enable_ai_insights {
            return Ok(());
        }
        
        let buffer = self.data_buffer.lock()
            .map_err(|_| TimeSeriesError::ComputationError("Failed to acquire buffer lock".to_string()))?;
        
        if buffer.len() < 100 {
            return Ok(()); // Need minimum data for meaningful insights
        }
        
        let data: Vec<(f64, f64)> = buffer.iter().copied().collect();
        let insights = self.generate_ai_insights(&data)?;
        self.ai_insights = Some(insights);
        
        Ok(())
    }
    
    /// Generate AI insights from data
    fn generate_ai_insights(&self, data: &[(f64, f64)]) -> Result<VisualInsights> {
        let values: Array1<f64> = data.iter().map(|(_, v)| *v).collect();
        
        // Pattern detection
        let patterns = self.detect_patterns(&values)?;
        
        // Generate visualization suggestions
        let suggestions = self.generate_visualization_suggestions(&values)?;
        
        // Detect visual anomalies
        let anomalies = self.detect_visual_anomalies(&values)?;
        
        // Statistical insights
        let statistical_insights = self.generate_statistical_insights(&values)?;
        
        // Correlation insights (if multiple series available)
        let correlation_insights = Vec::new(); // Would implement with multiple series
        
        Ok(VisualInsights {
            patterns,
            visualization_suggestions: suggestions,
            visual_anomalies: anomalies,
            statistical_insights,
            correlation_insights,
        })
    }
    
    /// Detect patterns in time series data
    fn detect_patterns(&self, data: &Array1<f64>) -> Result<Vec<PatternInsight>> {
        let mut patterns = Vec::new();
        
        // Detect seasonality using autocorrelation
        let seasonality_insight = self.detect_seasonality(data)?;
        if let Some(insight) = seasonality_insight {
            patterns.push(insight);
        }
        
        // Detect trends using linear regression
        let trend_insight = self.detect_trend(data)?;
        if let Some(insight) = trend_insight {
            patterns.push(insight);
        }
        
        // Detect anomalies using z-score
        let anomaly_insights = self.detect_anomalies(data)?;
        patterns.extend(anomaly_insights);
        
        Ok(patterns)
    }
    
    /// Detect seasonality patterns
    fn detect_seasonality(&self, data: &Array1<f64>) -> Result<Option<PatternInsight>> {
        if data.len() < 24 {
            return Ok(None);
        }
        
        // Simple autocorrelation for seasonal detection
        let max_lag = data.len().min(100);
        let mut max_correlation = 0.0;
        let mut best_period = 0;
        
        for lag in 2..max_lag {
            let correlation = self.calculate_autocorrelation(data, lag)?;
            if correlation > max_correlation {
                max_correlation = correlation;
                best_period = lag;
            }
        }
        
        if max_correlation > 0.5 { // Threshold for significant seasonality
            let mut parameters = HashMap::new();
            parameters.insert("period".to_string(), best_period as f64);
            parameters.insert("strength".to_string(), max_correlation);
            
            Ok(Some(PatternInsight {
                pattern_type: PatternType::Seasonal,
                confidence: max_correlation,
                start_index: 0,
                end_index: data.len() - 1,
                parameters,
                description: format!("Seasonal pattern detected with period {} and strength {:.2}", 
                                   best_period, max_correlation),
            }))
        } else {
            Ok(None)
        }
    }
    
    /// Calculate autocorrelation at specific lag
    fn calculate_autocorrelation(&self, data: &Array1<f64>, lag: usize) -> Result<f64> {
        if lag >= data.len() {
            return Ok(0.0);
        }
        
        let n = data.len() - lag;
        let mean = data.mean().unwrap_or(0.0);
        
        let mut numerator = 0.0;
        let mut denominator = 0.0;
        
        for i in 0..n {
            let x_i = data[i] - mean;
            let x_lag = data[i + lag] - mean;
            numerator += x_i * x_lag;
            denominator += x_i * x_i;
        }
        
        Ok(if denominator > 0.0 { numerator / denominator } else { 0.0 })
    }
    
    /// Detect trend patterns
    fn detect_trend(&self, data: &Array1<f64>) -> Result<Option<PatternInsight>> {
        let n = data.len() as f64;
        let x_sum = (0..data.len()).map(|i| i as f64).sum::<f64>();
        let y_sum = data.sum();
        let xy_sum = data.iter().enumerate()
            .map(|(i, &y)| i as f64 * y)
            .sum::<f64>();
        let x2_sum = (0..data.len()).map(|i| (i * i) as f64).sum::<f64>();
        
        let slope = (n * xy_sum - x_sum * y_sum) / (n * x2_sum - x_sum * x_sum);
        let intercept = (y_sum - slope * x_sum) / n;
        
        // Calculate R-squared for trend strength
        let y_mean = data.mean().unwrap_or(0.0);
        let ss_tot = data.iter().map(|&y| (y - y_mean).powi(2)).sum::<f64>();
        let ss_res = data.iter().enumerate()
            .map(|(i, &y)| {
                let predicted = slope * i as f64 + intercept;
                (y - predicted).powi(2)
            })
            .sum::<f64>();
        
        let r_squared = 1.0 - (ss_res / ss_tot);
        
        if r_squared > 0.1 && slope.abs() > 0.01 { // Thresholds for significant trend
            let mut parameters = HashMap::new();
            parameters.insert("slope".to_string(), slope);
            parameters.insert("intercept".to_string(), intercept);
            parameters.insert("r_squared".to_string(), r_squared);
            
            let trend_direction = if slope > 0.0 { "increasing" } else { "decreasing" };
            
            Ok(Some(PatternInsight {
                pattern_type: PatternType::Trend,
                confidence: r_squared,
                start_index: 0,
                end_index: data.len() - 1,
                parameters,
                description: format!("{} trend detected with R² = {:.3}", trend_direction, r_squared),
            }))
        } else {
            Ok(None)
        }
    }
    
    /// Detect anomaly patterns
    fn detect_anomalies(&self, data: &Array1<f64>) -> Result<Vec<PatternInsight>> {
        let mean = data.mean().unwrap_or(0.0);
        let std_dev = data.var(0.0).sqrt();
        let threshold = 3.0; // Z-score threshold
        
        let mut anomalies = Vec::new();
        
        for (i, &value) in data.iter().enumerate() {
            let z_score = (value - mean) / std_dev;
            
            if z_score.abs() > threshold {
                let mut parameters = HashMap::new();
                parameters.insert("z_score".to_string(), z_score);
                parameters.insert("value".to_string(), value);
                parameters.insert("deviation".to_string(), (value - mean).abs());
                
                anomalies.push(PatternInsight {
                    pattern_type: PatternType::Anomaly,
                    confidence: (z_score.abs() - threshold) / threshold,
                    start_index: i,
                    end_index: i,
                    parameters,
                    description: format!("Anomaly detected at index {} with z-score {:.2}", i, z_score),
                });
            }
        }
        
        Ok(anomalies)
    }
    
    /// Generate visualization suggestions
    fn generate_visualization_suggestions(&self, data: &Array1<f64>) -> Result<Vec<VisualizationSuggestion>> {
        let mut suggestions = Vec::new();
        
        // Always suggest basic time series plot
        suggestions.push(VisualizationSuggestion {
            plot_type: SuggestedPlotType::TimeSeries,
            rationale: "Basic time series visualization for temporal pattern analysis".to_string(),
            effectiveness_score: 0.9,
            parameters: HashMap::new(),
        });
        
        // Suggest autocorrelation if data shows potential patterns
        if data.len() > 50 {
            suggestions.push(VisualizationSuggestion {
                plot_type: SuggestedPlotType::AutocorrelationFunction,
                rationale: "Autocorrelation analysis to identify periodic patterns".to_string(),
                effectiveness_score: 0.7,
                parameters: HashMap::new(),
            });
        }
        
        // Suggest spectral analysis for frequency domain insights
        if data.len() > 100 {
            suggestions.push(VisualizationSuggestion {
                plot_type: SuggestedPlotType::SpectralDensity,
                rationale: "Frequency domain analysis to identify dominant cycles".to_string(),
                effectiveness_score: 0.6,
                parameters: HashMap::new(),
            });
        }
        
        Ok(suggestions)
    }
    
    /// Detect visual anomalies
    fn detect_visual_anomalies(&self, data: &Array1<f64>) -> Result<Vec<VisualAnomaly>> {
        let mut anomalies = Vec::new();
        
        // Check for data density issues (too many points in small area)
        if data.len() > 10000 {
            anomalies.push(VisualAnomaly {
                anomaly_type: VisualAnomalyType::VisualClutter,
                x: 0.0,
                y: 0.0,
                severity: 0.8,
                description: "High data density may cause visual clutter - consider decimation".to_string(),
            });
        }
        
        Ok(anomalies)
    }
    
    /// Generate statistical insights
    fn generate_statistical_insights(&self, data: &Array1<f64>) -> Result<Vec<StatisticalInsight>> {
        let mut insights = Vec::new();
        
        // Basic normality assessment using skewness and kurtosis
        let mean = data.mean().unwrap_or(0.0);
        let variance = data.var(0.0);
        let std_dev = variance.sqrt();
        
        // Calculate skewness
        let skewness = if std_dev > 0.0 {
            data.iter()
                .map(|&x| ((x - mean) / std_dev).powi(3))
                .sum::<f64>() / data.len() as f64
        } else {
            0.0
        };
        
        // Calculate kurtosis
        let kurtosis = if std_dev > 0.0 {
            data.iter()
                .map(|&x| ((x - mean) / std_dev).powi(4))
                .sum::<f64>() / data.len() as f64 - 3.0
        } else {
            0.0
        };
        
        // Assess normality
        let normality_score = if skewness.abs() < 0.5 && kurtosis.abs() < 0.5 {
            0.9
        } else if skewness.abs() < 1.0 && kurtosis.abs() < 1.0 {
            0.7
        } else {
            0.3
        };
        
        insights.push(StatisticalInsight {
            insight_type: StatisticalInsightType::NormalityTest,
            value: normality_score,
            confidence_interval: None,
            p_value: None,
            description: format!("Normality assessment: {:.1}% likely normal (skew: {:.2}, kurt: {:.2})", 
                               normality_score * 100.0, skewness, kurtosis),
        });
        
        Ok(insights)
    }
    
    /// Update performance metrics
    fn update_performance_metrics(&mut self) -> Result<()> {
        let now = Instant::now();
        let elapsed = now.duration_since(self.last_update);
        
        if elapsed >= self.update_frequency {
            // Calculate FPS
            self.performance_metrics.fps = 1.0 / elapsed.as_secs_f64();
            
            // Estimate memory usage (simplified)
            self.performance_metrics.memory_usage_mb = 
                (self.buffer_size * std::mem::size_of::<(f64, f64)>()) as f64 / 1_048_576.0;
            
            // Calculate data throughput
            self.performance_metrics.data_throughput = 1.0 / elapsed.as_secs_f64();
            
            self.last_update = now;
        }
        
        Ok(())
    }
    
    /// Get current performance metrics
    pub fn get_performance_metrics(&self) -> &PerformanceMetrics {
        &self.performance_metrics
    }
    
    /// Get current AI insights
    pub fn get_ai_insights(&self) -> Option<&VisualInsights> {
        self.ai_insights.as_ref()
    }
}

/// 3D Visualization capabilities
#[derive(Debug)]
pub struct Visualization3D {
    /// Configuration
    config: UltraPlotConfig,
    /// 3D data points
    data_points: Vec<Point3D>,
    /// Surface meshes
    pub surfaces: Vec<Surface3D>,
    /// Camera configuration
    camera: Camera3D,
    /// Lighting configuration
    lighting: LightingConfig,
}

/// 3D point representation
#[derive(Debug, Clone)]
pub struct Point3D {
    pub x: f64,
    pub y: f64,
    pub z: f64,
    pub color: Color,
    pub size: f64,
    pub metadata: HashMap<String, String>,
}

/// 3D surface representation
#[derive(Debug, Clone)]
pub struct Surface3D {
    /// Surface vertices
    pub vertices: Array2<Point3D>,
    /// Surface normals for lighting
    pub normals: Array2<Vector3D>,
    /// Surface material properties
    pub material: MaterialProperties,
}

/// 3D vector
#[derive(Debug, Clone, Copy)]
pub struct Vector3D {
    pub x: f64,
    pub y: f64,
    pub z: f64,
}

/// Color representation
#[derive(Debug, Clone, Copy)]
pub struct Color {
    pub r: f32,
    pub g: f32,
    pub b: f32,
    pub a: f32,
}

/// Material properties for 3D surfaces
#[derive(Debug, Clone)]
pub struct MaterialProperties {
    pub ambient: Color,
    pub diffuse: Color,
    pub specular: Color,
    pub shininess: f32,
    pub transparency: f32,
}

/// Camera configuration for 3D visualization
#[derive(Debug, Clone)]
pub struct Camera3D {
    pub position: Point3D,
    pub target: Point3D,
    pub up_vector: Vector3D,
    pub field_of_view: f64,
    pub near_plane: f64,
    pub far_plane: f64,
}

/// Lighting configuration
#[derive(Debug, Clone)]
pub struct LightingConfig {
    pub ambient_light: Color,
    pub directional_lights: Vec<DirectionalLight>,
    pub point_lights: Vec<PointLight>,
    pub spot_lights: Vec<SpotLight>,
}

/// Directional light source
#[derive(Debug, Clone)]
pub struct DirectionalLight {
    pub direction: Vector3D,
    pub color: Color,
    pub intensity: f32,
}

/// Point light source
#[derive(Debug, Clone)]
pub struct PointLight {
    pub position: Point3D,
    pub color: Color,
    pub intensity: f32,
    pub attenuation: (f32, f32, f32), // constant, linear, quadratic
}

/// Spot light source
#[derive(Debug, Clone)]
pub struct SpotLight {
    pub position: Point3D,
    pub direction: Vector3D,
    pub color: Color,
    pub intensity: f32,
    pub inner_cone_angle: f32,
    pub outer_cone_angle: f32,
}

impl Visualization3D {
    /// Create new 3D visualization
    pub fn new(config: UltraPlotConfig) -> Self {
        Self {
            config,
            data_points: Vec::new(),
            surfaces: Vec::new(),
            camera: Camera3D {
                position: Point3D { x: 10.0, y: 10.0, z: 10.0, color: Color { r: 1.0, g: 1.0, b: 1.0, a: 1.0 }, size: 1.0, metadata: HashMap::new() },
                target: Point3D { x: 0.0, y: 0.0, z: 0.0, color: Color { r: 1.0, g: 1.0, b: 1.0, a: 1.0 }, size: 1.0, metadata: HashMap::new() },
                up_vector: Vector3D { x: 0.0, y: 1.0, z: 0.0 },
                field_of_view: 45.0,
                near_plane: 0.1,
                far_plane: 1000.0,
            },
            lighting: LightingConfig {
                ambient_light: Color { r: 0.2, g: 0.2, b: 0.2, a: 1.0 },
                directional_lights: vec![
                    DirectionalLight {
                        direction: Vector3D { x: -1.0, y: -1.0, z: -1.0 },
                        color: Color { r: 1.0, g: 1.0, b: 1.0, a: 1.0 },
                        intensity: 0.8,
                    }
                ],
                point_lights: Vec::new(),
                spot_lights: Vec::new(),
            },
        }
    }
    
    /// Add 3D time series surface
    pub fn add_time_series_surface(&mut self, data: &Array2<f64>) -> Result<()> {
        let (rows, cols) = data.dim();
        let mut vertices = Array2::default((rows, cols));
        let mut normals = Array2::default((rows, cols));
        
        // Generate vertices
        for i in 0..rows {
            for j in 0..cols {
                vertices[[i, j]] = Point3D {
                    x: i as f64,
                    y: data[[i, j]],
                    z: j as f64,
                    color: self.value_to_color(data[[i, j]]),
                    size: 1.0,
                    metadata: HashMap::new(),
                };
            }
        }
        
        // Calculate normals for lighting
        for i in 1..rows-1 {
            for j in 1..cols-1 {
                let v1 = Vector3D {
                    x: 2.0,
                    y: data[[i+1, j]] - data[[i-1, j]],
                    z: 0.0,
                };
                let v2 = Vector3D {
                    x: 0.0,
                    y: data[[i, j+1]] - data[[i, j-1]],
                    z: 2.0,
                };
                
                // Cross product for normal
                normals[[i, j]] = Vector3D {
                    x: v1.y * v2.z - v1.z * v2.y,
                    y: v1.z * v2.x - v1.x * v2.z,
                    z: v1.x * v2.y - v1.y * v2.x,
                };
                
                // Normalize
                let length = (normals[[i, j]].x.powi(2) + 
                             normals[[i, j]].y.powi(2) + 
                             normals[[i, j]].z.powi(2)).sqrt();
                
                if length > 0.0 {
                    normals[[i, j]].x /= length;
                    normals[[i, j]].y /= length;
                    normals[[i, j]].z /= length;
                }
            }
        }
        
        let surface = Surface3D {
            vertices,
            normals,
            material: MaterialProperties {
                ambient: Color { r: 0.2, g: 0.2, b: 0.8, a: 1.0 },
                diffuse: Color { r: 0.6, g: 0.6, b: 1.0, a: 1.0 },
                specular: Color { r: 1.0, g: 1.0, b: 1.0, a: 1.0 },
                shininess: 64.0,
                transparency: 0.0,
            },
        };
        
        self.surfaces.push(surface);
        Ok(())
    }
    
    /// Add real-time streaming 3D data point
    pub fn add_streaming_point(&mut self, x: f64, y: f64, z: f64, metadata: HashMap<String, String>) -> Result<()> {
        let color = self.value_to_color(z); // Use Z-value for color mapping
        
        let point = Point3D {
            x,
            y, 
            z,
            color,
            size: 1.0,
            metadata,
        };
        
        self.data_points.push(point);
        
        // Limit buffer size for performance
        if self.data_points.len() > 100_000 {
            self.data_points.remove(0);
        }
        
        Ok(())
    }
    
    /// Update camera position for dynamic viewing
    pub fn update_camera(&mut self, position: Point3D, target: Point3D) {
        self.camera.position = position;
        self.camera.target = target;
    }
    
    /// Add dynamic lighting effect
    pub fn add_point_light(&mut self, position: Point3D, color: Color, intensity: f32) {
        let light = PointLight {
            position,
            color,
            intensity,
            attenuation: (1.0, 0.1, 0.01), // Realistic attenuation
        };
        
        self.lighting.point_lights.push(light);
    }
    
    /// Export VR/AR compatible visualization
    pub fn export_vr_compatible(&self, path: &str) -> Result<()> {
        let vr_content = format!(r#"
<!DOCTYPE html>
<html>
<head>
    <title>Ultra VR/AR Time Series Visualization</title>
    <script src="https://aframe.io/releases/1.4.0/aframe.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/donmccurdy/aframe-extras@v6.1.1/dist/aframe-extras.min.js"></script>
    <style>
        body {{ margin: 0; font-family: Arial, sans-serif; }}
        .vr-controls {{ position: absolute; top: 10px; left: 10px; z-index: 1000; color: white; }}
    </style>
</head>
<body>
    <div class="vr-controls">
        <h3>Ultra VR/AR Time Series</h3>
        <button onclick="enterVR()">Enter VR</button>
        <button onclick="enterAR()">Enter AR</button>
        <button onclick="toggleAnimation()">Toggle Animation</button>
    </div>
    
    <a-scene 
        embedded 
        arjs="sourceType: webcam; debugUIEnabled: false;" 
        vr-mode-ui="enabled: true"
        background="color: #000020">
        
        <!-- Assets -->
        <a-assets>
            <a-mixin id="surface-material" 
                     material="color: #4CC3D9; 
                              metalness: 0.2; 
                              roughness: 0.8;
                              transparent: true;
                              opacity: 0.8"></a-mixin>
        </a-assets>
        
        <!-- Lighting -->
        <a-light type="ambient" color="#404040" intensity="0.4"></a-light>
        <a-light type="directional" 
                 position="10 10 10" 
                 color="#ffffff" 
                 intensity="0.8"
                 light="castShadow: true"></a-light>
        
        <!-- 3D Time Series Surfaces -->
        <a-entity id="time-series-container" position="0 1.6 -3">
            <!-- Dynamic surfaces will be generated here -->
        </a-entity>
        
        <!-- Interactive Controls -->
        <a-entity id="controls" position="0 1.2 -2">
            <a-text value="Ultra Time Series Visualization"
                    position="0 0.5 0"
                    align="center"
                    color="#ffffff"
                    width="8"></a-text>
            
            <a-box position="-1 0 0" 
                   width="0.3" height="0.3" depth="0.3"
                   color="#ff6b6b"
                   class="clickable"
                   animation="property: rotation; to: 360 360 0; loop: true; dur: 5000">
                <a-text value="Reset" position="0 -0.5 0" align="center" width="8"></a-text>
            </a-box>
            
            <a-sphere position="1 0 0"
                      radius="0.15"
                      color="#4ecdc4"
                      class="clickable"
                      animation="property: scale; to: 1.2 1.2 1.2; dir: alternate; loop: true; dur: 1000">
                <a-text value="Animate" position="0 -0.4 0" align="center" width="8"></a-text>
            </a-sphere>
        </a-entity>
        
        <!-- VR Controllers -->
        <a-entity id="rig" position="0 1.6 3">
            <a-camera look-controls wasd-controls>
                <a-cursor color="#ffffff" 
                         raycaster="objects: .clickable"
                         animation__click="property: scale; startEvents: click; from: 0.1 0.1 0.1; to: 1 1 1; dur: 150">
                </a-cursor>
            </a-camera>
            
            <a-entity id="leftHand" 
                      hand-controls="hand: left; handModelStyle: lowPoly; color: #15ACCF">
            </a-entity>
            
            <a-entity id="rightHand" 
                      hand-controls="hand: right; handModelStyle: lowPoly; color: #15ACCF">
            </a-entity>
        </a-entity>
        
        <!-- Ground plane for reference -->
        <a-plane position="0 0 -4" 
                 rotation="-90 0 0" 
                 width="20" height="20" 
                 color="#1a1a2e" 
                 shadow="receive: true">
        </a-plane>
    </a-scene>
    
    <script>
        let animationEnabled = false;
        let vrMode = false;
        let arMode = false;
        
        function enterVR() {{
            document.querySelector('a-scene').enterVR();
            vrMode = true;
            console.log('Entered VR mode');
        }}
        
        function enterAR() {{
            // AR functionality would be implemented here
            arMode = true;
            console.log('Entered AR mode');
        }}
        
        function toggleAnimation() {{
            animationEnabled = !animationEnabled;
            console.log('Animation toggled:', animationEnabled);
            
            if (animationEnabled) {{
                startTimeSeriesAnimation();
            }} else {{
                stopTimeSeriesAnimation();
            }}
        }}
        
        function startTimeSeriesAnimation() {{
            // Real-time animation of time series data
            const container = document.getElementById('time-series-container');
            
            // Generate dynamic 3D surface based on time series data
            for (let i = 0; i < {}; i++) {{
                const surface = document.createElement('a-plane');
                surface.setAttribute('position', `${{i*2-5}} ${{Math.sin(i*0.5)*2}} 0`);
                surface.setAttribute('rotation', '0 0 45');
                surface.setAttribute('width', '1.5');
                surface.setAttribute('height', '1.5');
                surface.setAttribute('material', `color: hsl(${{i*40}}, 70%, 60%); transparent: true; opacity: 0.7`);
                surface.setAttribute('animation', 
                    `property: position; 
                     to: ${{i*2-5}} ${{Math.sin((i+1)*0.5)*2}} 0; 
                     loop: true; 
                     dir: alternate; 
                     dur: 3000`);
                container.appendChild(surface);
            }}
        }}
        
        function stopTimeSeriesAnimation() {{
            const container = document.getElementById('time-series-container');
            container.innerHTML = '';
        }}
        
        // Interactive event handlers
        document.querySelector('.clickable').addEventListener('click', function() {{
            console.log('Interactive element clicked in VR');
        }});
        
        // Real-time data updates (would integrate with Rust backend)
        setInterval(() => {{
            if (animationEnabled) {{
                updateVisualizationData();
            }}
        }}, 100);
        
        function updateVisualizationData() {{
            // Update 3D visualization with new time series data
            // This would receive data from the Rust backend
        }}
        
        console.log('Ultra VR/AR Time Series Visualization loaded');
    </script>
</body>
</html>
        "#, self.surfaces.len());
        
        std::fs::write(path, vr_content)
            .map_err(|e| TimeSeriesError::IOError(format!("Failed to write VR content: {}", e)))?;
        
        Ok(())
    }
    
    /// Convert data value to color
    fn value_to_color(&self, value: f64) -> Color {
        // Simple blue-to-red color mapping
        let normalized = (value + 1.0) / 2.0; // Assume values in [-1, 1]
        let clamped = normalized.max(0.0).min(1.0);
        
        Color {
            r: clamped as f32,
            g: 0.0,
            b: (1.0 - clamped) as f32,
            a: 1.0,
        }
    }
}

/// Export capabilities for ultra-advanced visualizations
pub struct UltraExporter;

impl UltraExporter {
    /// Export to interactive HTML with embedded JavaScript
    pub fn export_interactive_html(
        plot: &StreamingVisualization,
        path: &str,
    ) -> Result<()> {
        // Generate interactive HTML with D3.js, WebGL, and real-time capabilities
        let html_content = r#"
<!DOCTYPE html>
<html>
<head>
    <title>Ultra Time Series Visualization</title>
    <script src="https://d3js.org/d3.v7.min.js"></script>
    <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
    <style>
        body { font-family: Arial, sans-serif; margin: 0; padding: 20px; }
        .plot-container { width: 100%; height: 600px; margin: 20px 0; }
        .controls { margin: 20px 0; }
        .ai-insights { background: #f0f0f0; padding: 15px; border-radius: 5px; margin: 20px 0; }
    </style>
</head>
<body>
    <h1>Ultra Time Series Visualization</h1>
    <div class="controls">
        <button onclick="toggleRealTime()">Toggle Real-time</button>
        <button onclick="exportData()">Export Data</button>
        <button onclick="showInsights()">AI Insights</button>
    </div>
    <div id="plot" class="plot-container"></div>
    <div id="insights" class="ai-insights" style="display: none;"></div>
    
    <script>
        // Advanced interactive visualization code would go here
        // Including real-time updates, AI insights display, and export functionality
    </script>
</body>
</html>
        "#;
        
        std::fs::write(path, html_content)
            .map_err(|e| TimeSeriesError::IOError(format!("Failed to write HTML: {}", e)))?;
        
        Ok(())
    }
    
    /// Export to WebGL-based 3D visualization
    pub fn export_webgl_3d(
        plot: &Visualization3D,
        path: &str,
    ) -> Result<()> {
        // Generate WebGL-based 3D visualization with ultra-advanced shaders
        let webgl_content = format!(r#"
<!DOCTYPE html>
<html>
<head>
    <title>Ultra 3D Time Series WebGL Visualization</title>
    <style>
        body {{ margin: 0; padding: 0; background: #000; overflow: hidden; }}
        canvas {{ display: block; }}
        .controls {{ position: absolute; top: 10px; left: 10px; color: white; font-family: Arial; }}
        .fps-counter {{ position: absolute; top: 10px; right: 10px; color: white; font-family: Arial; }}
    </style>
</head>
<body>
    <canvas id="webgl-canvas"></canvas>
    <div class="controls">
        <button onclick="toggleRealTime()">Toggle Real-time</button>
        <button onclick="resetCamera()">Reset Camera</button>
        <button onclick="toggleWireframe()">Wireframe</button>
        <button onclick="toggleLighting()">Lighting</button>
    </div>
    <div class="fps-counter" id="fps">FPS: 0</div>
    
    <script>
    // Ultra-advanced WebGL 3D time series visualization
    const canvas = document.getElementById('webgl-canvas');
    const gl = canvas.getContext('webgl2') || canvas.getContext('webgl');
    
    if (!gl) {{
        console.error('WebGL not supported');
    }}
    
    // Vertex shader with advanced lighting
    const vertexShaderSource = `
        attribute vec3 a_position;
        attribute vec3 a_normal;
        attribute vec4 a_color;
        
        uniform mat4 u_modelViewMatrix;
        uniform mat4 u_projectionMatrix;
        uniform mat3 u_normalMatrix;
        uniform vec3 u_lightDirection;
        
        varying vec3 v_normal;
        varying vec4 v_color;
        varying float v_lighting;
        
        void main() {{
            gl_Position = u_projectionMatrix * u_modelViewMatrix * vec4(a_position, 1.0);
            
            v_normal = u_normalMatrix * a_normal;
            v_color = a_color;
            
            // Calculate basic directional lighting
            vec3 normal = normalize(v_normal);
            v_lighting = max(dot(normal, normalize(u_lightDirection)), 0.2);
        }}
    `;
    
    // Fragment shader with advanced material rendering
    const fragmentShaderSource = `
        precision mediump float;
        
        varying vec3 v_normal;
        varying vec4 v_color;
        varying float v_lighting;
        
        uniform bool u_wireframe;
        uniform float u_time;
        
        void main() {{
            vec4 color = v_color;
            
            if (u_wireframe) {{
                color = vec4(1.0, 1.0, 1.0, 1.0);
            }}
            
            // Apply lighting
            color.rgb *= v_lighting;
            
            // Add temporal effects for dynamic visualization
            float pulse = sin(u_time * 2.0) * 0.1 + 0.9;
            color.rgb *= pulse;
            
            gl_FragColor = color;
        }}
    `;
    
    // WebGL rendering pipeline setup
    function createShader(gl, type, source) {{
        const shader = gl.createShader(type);
        gl.shaderSource(shader, source);
        gl.compileShader(shader);
        
        if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {{
            console.error('Shader compilation error:', gl.getShaderInfoLog(shader));
            gl.deleteShader(shader);
            return null;
        }}
        
        return shader;
    }}
    
    function createProgram(gl, vertexShader, fragmentShader) {{
        const program = gl.createProgram();
        gl.attachShader(program, vertexShader);
        gl.attachShader(program, fragmentShader);
        gl.linkProgram(program);
        
        if (!gl.getProgramParameter(program, gl.LINK_STATUS)) {{
            console.error('Program linking error:', gl.getProgramInfoLog(program));
            gl.deleteProgram(program);
            return null;
        }}
        
        return program;
    }}
    
    // Initialize WebGL program
    const vertexShader = createShader(gl, gl.VERTEX_SHADER, vertexShaderSource);
    const fragmentShader = createShader(gl, gl.FRAGMENT_SHADER, fragmentShaderSource);
    const program = createProgram(gl, vertexShader, fragmentShader);
    
    // Ultra-advanced 3D rendering loop with real-time updates
    let frameCount = 0;
    let lastTime = 0;
    let realTimeMode = false;
    let wireframeMode = false;
    let lightingEnabled = true;
    
    function render(currentTime) {{
        // FPS calculation
        frameCount++;
        if (currentTime - lastTime >= 1000) {{
            document.getElementById('fps').textContent = 'FPS: ' + frameCount;
            frameCount = 0;
            lastTime = currentTime;
        }}
        
        // Clear and setup
        gl.clearColor(0.0, 0.0, 0.0, 1.0);
        gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);
        gl.enable(gl.DEPTH_TEST);
        
        // Use shader program
        gl.useProgram(program);
        
        // Set uniforms for ultra-advanced effects
        const timeLocation = gl.getUniformLocation(program, 'u_time');
        gl.uniform1f(timeLocation, currentTime * 0.001);
        
        const wireframeLocation = gl.getUniformLocation(program, 'u_wireframe');
        gl.uniform1i(wireframeLocation, wireframeMode);
        
        // Render 3D surfaces with advanced material properties
        // (Surface data would be uploaded from Rust visualization)
        
        requestAnimationFrame(render);
    }}
    
    // Control functions
    function toggleRealTime() {{
        realTimeMode = !realTimeMode;
        console.log('Real-time mode:', realTimeMode);
    }}
    
    function resetCamera() {{
        console.log('Camera reset');
    }}
    
    function toggleWireframe() {{
        wireframeMode = !wireframeMode;
        console.log('Wireframe mode:', wireframeMode);
    }}
    
    function toggleLighting() {{
        lightingEnabled = !lightingEnabled;
        console.log('Lighting enabled:', lightingEnabled);
    }}
    
    // Resize canvas
    function resizeCanvas() {{
        canvas.width = window.innerWidth;
        canvas.height = window.innerHeight;
        gl.viewport(0, 0, canvas.width, canvas.height);
    }}
    
    window.addEventListener('resize', resizeCanvas);
    resizeCanvas();
    
    // Start ultra-advanced rendering
    requestAnimationFrame(render);
    
    </script>
</body>
</html>
        "#, plot.surfaces.len());
        
        std::fs::write(path, webgl_content)
            .map_err(|e| TimeSeriesError::IOError(format!("Failed to write WebGL 3D: {}", e)))?;
        
        Ok(())
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    
    #[test]
    fn test_streaming_visualization() {
        let config = UltraPlotConfig::default();
        let mut viz = StreamingVisualization::new(config, 1000);
        
        // Add test data
        for i in 0..100 {
            let time = i as f64;
            let value = (time * 0.1).sin() + (time * 0.02).cos() * 0.5;
            viz.add_data_point(time, value).unwrap();
        }
        
        // Update AI insights
        viz.update_ai_insights().unwrap();
        
        // Check that insights were generated
        let insights = viz.get_ai_insights();
        assert!(insights.is_some());
        
        let insights = insights.unwrap();
        assert!(!insights.patterns.is_empty() || !insights.visualization_suggestions.is_empty());
    }
    
    #[test]
    fn test_pattern_detection() {
        let config = UltraPlotConfig::default();
        let mut viz = StreamingVisualization::new(config, 1000);
        
        // Generate data with clear seasonal pattern
        for i in 0..200 {
            let time = i as f64;
            let value = (time * 2.0 * std::f64::consts::PI / 24.0).sin(); // 24-period seasonality
            viz.add_data_point(time, value).unwrap();
        }
        
        viz.update_ai_insights().unwrap();
        
        let insights = viz.get_ai_insights().unwrap();
        let seasonal_patterns: Vec<_> = insights.patterns.iter()
            .filter(|p| matches!(p.pattern_type, PatternType::Seasonal))
            .collect();
        
        assert!(!seasonal_patterns.is_empty());
        
        // Check that period is detected correctly
        if let Some(pattern) = seasonal_patterns.first() {
            let period = pattern.parameters.get("period").unwrap();
            assert!((period - 24.0).abs() < 2.0); // Allow some tolerance
        }
    }
    
    #[test]
    fn test_3d_visualization() {
        let config = UltraPlotConfig::default();
        let mut viz = Visualization3D::new(config);
        
        // Create test surface data
        let mut data = Array2::zeros((10, 10));
        for i in 0..10 {
            for j in 0..10 {
                data[[i, j]] = ((i as f64 - 5.0).powi(2) + (j as f64 - 5.0).powi(2)).sqrt();
            }
        }
        
        viz.add_time_series_surface(&data).unwrap();
        
        assert_eq!(viz.surfaces.len(), 1);
        assert_eq!(viz.surfaces[0].vertices.dim(), (10, 10));
    }
    
    #[test]
    fn test_performance_metrics() {
        let config = UltraPlotConfig::default();
        let mut viz = StreamingVisualization::new(config, 100);
        
        // Add data and check performance metrics
        for i in 0..50 {
            viz.add_data_point(i as f64, i as f64).unwrap();
        }
        
        let metrics = viz.get_performance_metrics();
        assert!(metrics.memory_usage_mb >= 0.0);
        assert!(metrics.data_throughput >= 0.0);
    }
    
    #[test]
    fn test_ai_insights_generation() {
        let config = UltraPlotConfig {
            enable_ai_insights: true,
            auto_pattern_detection: true,
            ..Default::default()
        };
        let mut viz = StreamingVisualization::new(config, 1000);
        
        // Add trend data
        for i in 0..150 {
            let time = i as f64;
            let value = time * 0.1 + (time * 0.1).sin() * 0.5; // Trend + noise
            viz.add_data_point(time, value).unwrap();
        }
        
        viz.update_ai_insights().unwrap();
        
        let insights = viz.get_ai_insights().unwrap();
        
        // Should detect trend
        let trend_patterns: Vec<_> = insights.patterns.iter()
            .filter(|p| matches!(p.pattern_type, PatternType::Trend))
            .collect();
        
        assert!(!trend_patterns.is_empty());
        
        // Should have visualization suggestions
        assert!(!insights.visualization_suggestions.is_empty());
        
        // Should have statistical insights
        assert!(!insights.statistical_insights.is_empty());
    }
}